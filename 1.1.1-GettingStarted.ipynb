{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000022913BBB880> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022913BE91E0> root_client=<openai.OpenAI object at 0x0000022910FCA950> root_async_client=<openai.AsyncOpenAI object at 0x0000022913BBB8B0> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence systems that are designed to generate new content or data that is similar to the data they were trained on. This can include text, images, music, code, and even video. These systems use various machine learning techniques, particularly deep learning models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), to create new, original outputs.\\n\\nHere are some key points about generative AI:\\n\\n1. **Generative Adversarial Networks (GANs)**: GANs consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates new data samples, while the discriminator evaluates them. The goal is for the generator to produce data that is indistinguishable from real data to the discriminator.\\n\\n2. **Variational Autoencoders (VAEs)**: VAEs are another type of generative model that learn to encode input data into a latent space and then decode it back to recreate the original data. VAEs can also generate new data by sampling from the latent space and decoding it.\\n\\n3. **Applications**:\\n   - **Text Generation**: Language models like GPT-3 can generate coherent and contextually relevant text based on given prompts.\\n   - **Image Generation**: GANs can create realistic images from scratch or based on textual descriptions.\\n   - **Music Composition**: AI models can compose new pieces of music in various styles.\\n   - **Code Generation**: AI can assist in writing code or even generate new snippets based on descriptions.\\n\\n4. **Creative Assistance**: Generative AI is increasingly used in creative fields to assist artists, writers, and designers by providing inspiration or automating certain tasks.\\n\\n5. **Ethical Considerations**: The ability of generative AI to create realistic content has raised concerns about deepfakes, misinformation, and intellectual property rights. Ensuring responsible use and addressing ethical implications is an ongoing challenge.\\n\\nOverall, generative AI is a powerful tool with a wide range of applications, but it also requires careful consideration of its potential impacts on society.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 13, 'total_tokens': 439}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5', 'finish_reason': 'stop', 'logprobs': None} id='run-def77c03-1415-420e-bd7a-0d2bfab677ea-0' usage_metadata={'input_tokens': 13, 'output_tokens': 426, 'total_tokens': 439}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Certainly! LangSmith is a platform or tool designed to enhance the development and evaluation of applications that utilize Large Language Models (LLMs). It provides developers with robust tools to trace, visualize, and assess the performance of their LLM-powered applications, making it easier to refine and optimize these applications over time.\\n\\nKey features of LangSmith include:\\n\\n1. **Tracing and Visualization**: LangSmith offers detailed tracing capabilities that help developers understand the flow of data and logic within their LLM applications. This includes visual representations of how data moves through the system, which can be invaluable for debugging and optimization.\\n\\n2. **Evaluation Tools**: LangSmith includes tools to evaluate the performance of LLMs in various tasks. This could involve metrics for accuracy, response time, and other relevant factors that affect the performance of language models in real-world scenarios.\\n\\n3. **Integration with LangChain**: LangSmith is fully integrated with LangChain, a framework for developing applications with LLMs. This integration ensures that developers can seamlessly use LangSmith's features within the LangChain environment, providing a cohesive and efficient development experience.\\n\\n4. **Iterative Improvement**: By offering insights into the performance and behavior of LLM applications, LangSmith enables developers to make data-driven decisions for iterative improvements. This leads to more effective and reliable language model applications.\\n\\nOverall, LangSmith aims to streamline the process of creating, debugging, and optimizing applications that rely on large language models, thereby accelerating the development cycle and enhancing the quality of the final product. If you have any specific questions or need more detailed information about any aspect of LangSmith, feel free to ask!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 328, 'prompt_tokens': 33, 'total_tokens': 361}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5', 'finish_reason': 'stop', 'logprobs': None} id='run-ffb74d10-a73e-4bac-a8aa-9c974e431f23-0' usage_metadata={'input_tokens': 33, 'output_tokens': 328, 'total_tokens': 361}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! As of my last update in October 2023, there isn't a specific technology or concept widely recognized under the name \"Langsmith.\" It is possible that \"Langsmith\" could refer to a new tool, platform, or company that emerged after my last update, or it could be a niche term within a particular field.\n",
      "\n",
      "However, if you are referring to a concept or term coined within a specific context or a newly developed technology, I would need more details to provide an accurate explanation. If Langsmith is related to a recent development in AI, programming, or another tech domain, you might want to check the latest sources or specify the context for more precise information.\n",
      "\n",
      "Feel free to provide additional context or clarify your question further!\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
